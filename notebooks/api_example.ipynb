{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "\n",
    "from modeldiff import ModelDiff\n",
    "from src.data import datasets\n",
    "from src.data import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_metadata = pd.read_pickle('metadata/living17_val_metadata.df')\n",
    "class_names = dict(zip(_metadata['class'], _metadata['class_name'].apply(lambda s: s[:10])))\n",
    "\n",
    "IMAGENET_DIR = '/mnt/cfs/datasets/pytorch_imagenet' \n",
    "living17_tf = transforms.LIVING17_TRANSFORMS['val']\n",
    "\n",
    "dsets = {\n",
    "    'val': datasets.Living17('val', living17_tf, imagenet_dir=IMAGENET_DIR),\n",
    "    'train': datasets.Living17('train', living17_tf, imagenet_dir=IMAGENET_DIR)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_to_parameters(vec, parameters) -> None:\n",
    "    pointer = 0\n",
    "    for param in parameters:\n",
    "        num_param = param.numel()\n",
    "        param.data = vec[pointer:pointer + num_param].view_as(param).data\n",
    "        pointer += num_param\n",
    "\n",
    "# for loading checkpoints\n",
    "def from_npy_to_state_dict(ndarr, model):\n",
    "    ndarr = torch.from_numpy(ndarr).cuda()\n",
    "    PARAM_LEN = 11185233\n",
    "    sd_list = []\n",
    "\n",
    "    for v in ndarr:\n",
    "        params = v[:PARAM_LEN].float()\n",
    "        buffs = v[PARAM_LEN:].float()\n",
    "        vector_to_parameters(torch.tensor(params), model.parameters())\n",
    "        vector_to_parameters(torch.tensor(buffs), model.buffers())\n",
    "        model.eval()\n",
    "        sd_list.append(model.state_dict().copy())\n",
    "\n",
    "    return sd_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the models we want to compare.\n",
    "For simplicity, we will use the same architecture for both models (though this is not necessary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelA = torchvision.models.resnet18()\n",
    "modelA.fc = torch.nn.Linear(512, 17)\n",
    "modelA.eval()\n",
    "modelA.cuda() \n",
    "\n",
    "modelB = torchvision.models.resnet18()\n",
    "modelB.fc = torch.nn.Linear(512, 17)\n",
    "modelB.eval()\n",
    "modelB.cuda();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the training set\n",
    "Has to be the same for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=dsets['train'], batch_size=128, num_workers=3, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load checkpoints\n",
    "Load multiple model checkpoints in order to compute TRAK attribution scores. For more details, check out TRAK's [repo](https://github.com/MadryLab/trak) (and TRAK's [quickstart](https://trak.readthedocs.io/en/latest/quickstart.html)).\n",
    "\n",
    "The expected format is a list of `state_dict`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_713923/3086413736.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  vector_to_parameters(torch.tensor(params), model.parameters())\n",
      "/tmp/ipykernel_713923/3086413736.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  vector_to_parameters(torch.tensor(buffs), model.buffers())\n"
     ]
    }
   ],
   "source": [
    "# run scripts/download_living17_checkpoints.sh first\n",
    "all_ckpts = torch.load(Path('../checkpoints/living17.pt'))\n",
    "ckptsA = from_npy_to_state_dict(all_ckpts['with data aug'], modelA)[:5] # take the ckpts of the first 5 models\n",
    "ckptsB = from_npy_to_state_dict(all_ckpts['without data aug'], modelB)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the `ModelDiff` instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:TRAK:TRAK is still in an early 0.x.x version.\n",
      "                             Report any issues at https://github.com/MadryLab/trak/issues\n",
      "INFO:STORE:No existing model IDs in /mnt/xfs/home/krisgrg/projects/modeldiff/notebooks/modeldiff_scores/modelA.\n",
      "INFO:STORE:No existing TRAK scores in /mnt/xfs/home/krisgrg/projects/modeldiff/notebooks/modeldiff_scores/modelA.\n",
      "WARNING:TRAK:TRAK is still in an early 0.x.x version.\n",
      "                             Report any issues at https://github.com/MadryLab/trak/issues\n",
      "INFO:STORE:No existing model IDs in /mnt/xfs/home/krisgrg/projects/modeldiff/notebooks/modeldiff_scores/modelB.\n",
      "INFO:STORE:No existing TRAK scores in /mnt/xfs/home/krisgrg/projects/modeldiff/notebooks/modeldiff_scores/modelB.\n"
     ]
    }
   ],
   "source": [
    "md = ModelDiff(modelA, modelB, ckptsA, ckptsB, train_loader=train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take any `diff` of choice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can compute `A-B` and `B-A` with just a single line of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader1 = DataLoader(dataset=dsets['val'], batch_size=128, num_workers=3, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff1 = md.get_A_minus_B(val_loader=val_loader1, num_pca_comps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've initialized the `md` instance, we can use it to compute `diff`s wrt many different target datasets (e.g., like with `val_loader1` above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader2 = DataLoader(dataset=dsets['val'][0:127], batch_size=128, num_workers=3, pin_memory=True)\n",
    "diff2 = md.get_B_minus_A(val_loader=val_loader2, num_pca_comps=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bring Your Own Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you already have some attribution scores computed, you can still use the same API!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_from_scores = ModelDiff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run scripts/download_living17_checkpoints.sh first\n",
    "from pathlib import Path\n",
    "\n",
    "scores_dir = Path('./datamodels/')\n",
    "scoresA = torch.load(scores_dir.joinpath('living17_data-aug.pt'))['weight']\n",
    "scoresB = torch.load(scores_dir.joinpath('living17_without-data-aug.pt'))['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = md_from_scores.get_A_minus_B_from_scores(scoresA, scoresB, num_pca_comps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'directions': array([[-0.00066547,  0.00221916,  0.00012629, ...,  0.00020184,\n",
       "         -0.00036254, -0.00049859],\n",
       "        [-0.00524965, -0.00065124, -0.00038203, ...,  0.00063359,\n",
       "         -0.0018108 , -0.00165741]], dtype=float32),\n",
       " 'projections': array([[ 5.1245297e-04, -2.4516261e-04],\n",
       "        [-1.0042154e-04,  5.1465724e-04],\n",
       "        [-3.7063823e-05,  8.0200400e-05],\n",
       "        ...,\n",
       "        [-1.7703998e-05,  2.1589889e-04],\n",
       "        [-8.5801890e-05, -1.4266069e-04],\n",
       "        [-5.9207014e-05,  5.5971013e-05]], dtype=float32),\n",
       " 'variances': {'A': array([0.00033447, 0.00109441], dtype=float32),\n",
       "  'B': array([0.00012626, 0.00037166], dtype=float32)}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
